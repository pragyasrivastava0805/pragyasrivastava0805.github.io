<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Pragya Srivastava</title>
  <meta name="google-site-verification" content="tTnhER1B7VpkPPCjXelukKzHmzNz4ptE32kZ2CFTXBc" />
  <meta name="author" content="Pragya Srivastava">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
    <tbody>
      <tr>
        <td>
          <!-- HEADER SECTION -->
          <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:2.5%;width:63%;vertical-align:middle;">
                  <p style="text-align:center;font-size:1.8em;font-weight:bold;">Pragya Srivastava</p>
                  <p>
                    I am a researcher at <a href="https://research.google/teams/india-research-lab/">Google DeepMind</a>, working on Robust and Sample Efficient Reinforcement Learning for post-training with
                    <a href="https://sites.google.com/view/karthikeyan-shanmugam">Dr. Karthikeyan Shanmugam</a>,
                    <a href="https://scholar.google.com/citations?user=pWE12D4AAAAJ&hl=en">Dr. Aravindan Raghuveer</a>, and
                    <a href="https://rl.cs.mcgill.ca/people/doina-precup/">Prof. Doina Precup</a>.
                  </p>
                  <p>
                    Previously, I was a Research Intern at <a href="https://vita-group.github.io/research.html">VITA, UT Austin</a>, where I worked on the theoretical analysis of Structured State Space Models.
                    I also had the pleasure to work with <a href="https://amitsharma.in/">Dr. Amit Sharma</a> and
                    <a href="https://www.microsoft.com/en-us/research/people/amitdesh/">Dr. Amit Deshpande</a> at
                    <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/">Microsoft Research, India</a>,
                    where I worked on In-context Learning and OOD detection in Reward models.
                    Before this, I completed my undergrad from <a href="https://home.iitd.ac.in/">Indian Institute of Technology, Delhi</a>, with a major in Engineering Physics.
                    During this time, I was a research intern at UCSD, advised by <a href="https://pengtaoxie.github.io/">Prof. Pengtao Xie</a>,
                    and at the <a href="https://cs.stanford.edu/~ermon/website/">Ermon Group, Stanford University</a>.
                  </p>
                  <p style="text-align:center;">
                    <a href="mailto:pragya8srivastava@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/Pragya_CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=1OYQfxwAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                    <a href="https://x.com/Pragya2k">X</a> &nbsp;/&nbsp;
                    <a href="https://github.com/pragyasrivastava0805/">Github</a>
                  </p>
                </td>

                <td style="padding:2.5%;width:30%;max-width:30%;">
                  <a href="images/Pragya_CCD.jpg">
                    <img style="width:80%;max-width:80%;" alt="profile photo" src="images/Pragya_CCD.jpg">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- RESEARCH SECTION -->
          <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle;">
                  <h2>Research</h2>
                  <p>
                    My research focuses on identifying and characterizing the fundamental failure modes of existing AI alignment methods. I am keen in developing principled approaches to enable reasoning models to explore effectively through interventional feedback, and generalize robustly out-of-domains. Broadly, I aim to bridge the gap between theoretical learning algorithms and practical deployment to build models that are highly capable yet fundamentally safe.
                </td>
              </tr>
            </tbody>
          </table>

          <!-- PROJECTS SECTION -->
          <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
            <tbody>

              <!-- Project 1 -->
              <tr height="200px">
                <td style="padding:20px;width:30%;vertical-align:middle;">
                  <img src="images/anomaly-detection.jpeg" alt="Anomaly Detection" width="100%">
                </td>
                <td valign="middle">
                  <span class="papertitle">Benchmarking Anomaly Detection for Large Language Model Alignment</span>
                  <br>Dylan Feng*, <strong>Pragya Srivastava*</strong>, Anca Dragan, Cassidy Laidlaw
                  <br><br><strong>Under Review, 2025</strong>
                  <br><span style="color:#888;">[Paper Coming Soon]</span>
                  <p>Benchmarking detection of unforeseen alignment failures using scalable oversight.</p>
                </td>
              </tr>

              <!-- Project 2 -->
              <tr height="200px">
                <td style="padding:20px;width:30%;vertical-align:middle;">
                  <img src="images/causal_rob_rm.jpeg" alt="Causal Rubrics" width="100%">
                </td>
                <td valign="middle">
                  <a href="https://arxiv.org/abs/2506.16507">
                    <span class="papertitle">Robust Reward Modeling via Causal Rubrics</span>
                  </a>
                  <br><strong>Pragya Srivastava*</strong>, Harman Singh*, Rahul Madhavan*, Gandharv Patil, Sravanti Addepalli, Arun Suggala, Rengarajan Aravamudhan, Soumya Sharma, Anirban Laha, Aravindan Raghuveer, Karthikeyan Shanmugam, Doina Precup
                  <br><br><strong>Under Review, 2025</strong>
                  <br>
                  <em><a href="https://dataworldicml2025.github.io/">DataWorld Workshop</a> and
                  <a href="https://sites.google.com/corp/view/mhf-icml2025">MoFA Workshop</a> at ICML 2025</em>
                  <p>Developing robust reward models with reduced reliance on spurious attributes and higher sensitivity to causal rubrics.</p>
                </td>
              </tr>

              <!-- Project 3 -->
            <tr height="200px">
                <td style="padding:20px;width:30%;vertical-align:middle;">
                  <img src="images/uncertain-rm.png" alt="Uncertain RM" width="100%">
                </td>
                <td valign="middle">
                  <a href="https://openreview.net/forum?id=SUNOO5qL3x">
                    <span class="papertitle">Outlier-Aware Preference Optimization for Large Language Models</span>
                  </a>
                  <br><strong>Pragya Srivastava</strong>, Sai Soumya Nalli, Amit Deshpande, Amit Sharma
                  <br><br><span style="color:#888;">[Paper Coming Soon]</span>
                  <br>
                  <em><a href="https://bialign-workshop.github.io">BiAlign Workshop</a> and
                  <a href="https://uncertainty-foundation-models.github.io">Quantify Uncertainty Workshop</a> at ICLR 2025</em>
                  <p>Dynamic alignment method using energy-based OOD scoring to identify misjudgments and refine both policy and reward model.</p>
                </td>
              </tr>

              <!-- Project 4 -->
              <tr height="200px">
                <td style="padding:20px;width:30%;vertical-align:middle;">
                  <img src="images/ssm-bottlenecks.jpeg" alt="SSM Bottlenecks" width="100%">
                </td>
                <td valign="middle">
                  <a href="https://arxiv.org/abs/2501.00658">
                    <span class="papertitle">Understanding and Mitigating Bottlenecks of State Space Models through the Lens of Recency and Over-smoothing</span>
                  </a>
                  <br>Peihao Wang, Ruisi Cai, Yuehao Wang, Jiajun Zhu, <strong>Pragya Srivastava</strong>, Zhangyang Wang, Pan Li
                  <br><br><strong>ICLR 2025</strong>
                  <p>We reveal two core limitations of state space models—recency bias and over-smoothing—and propose a polarization technique improving long-range memory and stability.</p>
                </td>
              </tr>

              <!-- Project 5 -->
              <tr height="200px">
                <td style="padding:20px;width:30%;vertical-align:middle;">
                  <img src="images/nice.jpeg" alt="NICE" width="100%">
                </td>
                <td valign="middle">
                  <a href="https://arxiv.org/pdf/2402.06733">
                    <span class="papertitle">NICE: To Optimize In-Context Examples or Not?</span>
                  </a>
                  <br><strong>Pragya Srivastava*</strong>, Satvik Golechha*, Amit Deshpande, Amit Sharma [*Equal Contribution]
                  <br><br><strong>ACL 2024 (Main Conference)</strong>
                  <p>We introduce a task-specific metric, NICE (Normalized Invariability to Choice of Examples), that quantifies task learnability and guides whether to optimize instructions or ICEs.</p>
                </td>
              </tr>

              <!-- Project 6 -->
              <tr height="200px">
                <td style="padding:20px;width:30%;vertical-align:middle;">
                  <img src="images/table-understanding.jpeg" alt="Semi-Structured Reasoning" width="100%">
                </td>
                <td valign="middle">
                  <a href="https://arxiv.org/abs/2402.11194">
                    <span class="papertitle">Evaluating LLMs' Mathematical Reasoning in Financial Document Question Answering</span>
                  </a>
                  <br><strong>Pragya Srivastava*</strong>, Manuj Malik*, Vivek Gupta, Tanuja Ganu, Dan Roth [*Equal Contribution]
                  <br><br><strong>ACL 2024 (Findings)</strong>
                  <p>LLMs perform well on simple tasks but degrade sharply with table complexity, requiring deeper reasoning and multi-row inference.</p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- SERVICE SECTION -->
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle;text-align:center;">
                  Reviewer for ICLR 2026, ICML 2025 MoFA Workshop
                </td>
              </tr>
            </tbody>
          </table>

          <small>
            <center>Website template by <a href="https://github.com/jonbarron/website">Jon Barron</a></center>
          </small>

        </td>
      </tr>
    </tbody>
  </table>
</body>
</html>
